{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs   \n",
    "- [2023/03/08]   \n",
    "  Restart this notebook if you change the scratch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, List\n",
    "from scratch.probability import Probability as prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "  'font.size': 16,\n",
    "  'grid.alpha': 0.25})\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *science* part of data science frequently involves forming and testing *hypotheses* about our data and the process that generate it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Hypothesis Testing\n",
    "\n",
    "Hypothesis -> statistics (distributions) -> how likely the hypothesis holds\n",
    "\n",
    "**Null hypothesis**, $H_0$: some default position    \n",
    "**Alternative hypothesis**, $H_1$: other hypotheses that we would like to compare with $H_0$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Flipping a Coin\n",
    "\n",
    "**Null hypothesis**, $H_0$: The coin is fair ($p = 0.5$)    \n",
    "**Alternative hypothesis**, $H_1$: ($p \\neq 0.5$)\n",
    "\n",
    "In our test, we flip the coin at some number $n$ times, \n",
    "and count the nubmer of heads $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_approximation_to_binomial(\n",
    "  n: int, p: float) -> Tuple[float, float]:\n",
    "\n",
    "  \"\"\"Returns mu and sigma corresponding to a Binomial(n, p)\"\"\" \n",
    "  mu = p * n\n",
    "  sigma = np.sqrt(p * (1 - p) * n)\n",
    "  return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The normal cdf _is_ the probability the variable is below a threshold\n",
    "normal_probability_below = prob.normal_cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's above the threshold if it's not below the threshold\n",
    "def normal_probability_above(low: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "  \"\"\"The probability that an N(mu, sigma) is greater than lo.\"\"\" \n",
    "  return 1 - prob.normal_cdf(low, mu, sigma)\n",
    "\n",
    "# It's between if it's less than `high`, but not less than `low`\n",
    "def normal_probability_between(low: float, high: float,\n",
    "  mu: float = 0, sigma: float = 1) -> float:\n",
    "  \"\"\"The probability that an N(mu, sigma) is between `low` and `high`.\"\"\" \n",
    "  return prob.normal_cdf(high, mu, sigma) - prob.normal_cdf(low, mu, sigma)\n",
    "\n",
    "# it's outside if it's not between\n",
    "def normal_probability_outside(low: float, high: float, \n",
    "  mu: float = 0, sigma: float = 1) -> float:\n",
    "  \"\"\"The probability that an N(mu, sigma) is not between low and high.\"\"\" \n",
    "  return 1 - normal_probability_between(low, high, mu, sigma)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the upper, lower, or two-sided bounds given the probability\n",
    "symmetric to the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_upper_bound(probability: float, mu: float = 0,\n",
    "  sigma: float = 1) -> float:\n",
    "  \"\"\"Returns the z for which P(Z <= z) = probability\"\"\" \n",
    "  return prob.inverse_normal_cdf(probability, mu, sigma)\n",
    "\n",
    "def normal_lower_bound(probability: float, mu: float = 0, \n",
    "  sigma: float = 1) -> float:\n",
    "  \"\"\"Returns the z for which P(Z >= z) = probability\"\"\"\n",
    "  return prob.inverse_normal_cdf(1 - probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability: float, mu: float = 0,\n",
    "  sigma: float = 1) -> Tuple[float, float]:\n",
    "  \"\"\"\n",
    "  Returns the symmetric (about the mean) bounds that contains\n",
    "  the specified probability\n",
    "  \"\"\"  \n",
    "  tail_probability = (1 - probability) / 2\n",
    "\n",
    "  # upper bound should have tail_probability above it\n",
    "  upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
    "\n",
    "  # lower bound should have tail_probability below it\n",
    "  lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
    "\n",
    "  return lower_bound, upper_bound"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 1 error\n",
    "\n",
    "Let's say that we choose to flip  the coind $n = 1,000$ times.\n",
    "If our hyphotesis of fairness is true, $X$ (the number of head)\n",
    "should be distributed approximately normally with mean $np = 1,000 (0.5) = 500$ and standard deviation ($\\sqrt{np(1-p)} = \\sqrt{1,000(0.5)(0.5)} = 15.81$\n",
    "\n",
    "We need to make a decision about *significance* &mdash; how willing are to make a *type 1 error* (\"false positive\"), in which we reject $H_0$ even though it's true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500.0, 15.811388300841896)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_0, sigma_0 = normal_approximation_to_binomial(1_000, 0.5)\n",
    "mu_0, sigma_0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the test that rejects $H_0$ if $X$ fails outside the bounds\n",
    "given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower bound: 469\n",
      "upper_bound: 531\n"
     ]
    }
   ],
   "source": [
    "# significance level = 0.05 = 5%\n",
    "lower_bound, upper_bound = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "print(f\"lower bound: {lower_bound:.0f}\")\n",
    "print(f\"upper_bound: {upper_bound:.0f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumming $p$ really equals 0.5 (i.e., $H_0$ is true), \n",
    "there is just a 5% chance we observe an $X$ that lies outside this interval, which is the exact significance we wanted. \n",
    "Said differenelty, if $H_0$ is true, then, approximately 19 times\n",
    "out of $20$, this test will give the correct result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 2 error\n",
    "\n",
    "We are also often interested in the *power* of a test, which is\n",
    "the probability of not making a *type 2 error* (\"false negative\"),\n",
    "in which we fail to reject $H_0$ even though it's false.\n",
    "\n",
    "We assume that the coind is slightly biased toward heads ($p = 0.55$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_1: 550.0\n",
      "sigma_1: 15.732132722552274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.886548001295367"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fail to reject H_0 means that we fall inside the interval of 95% bound.\n",
    "# 95% bounds based on assumption p is 0.5 (H_0)\n",
    "low, high = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "\n",
    "# actual mu and sigma based on p = 0.55\n",
    "mu_1, sigma_1 = normal_approximation_to_binomial(1_000, 0.55)\n",
    "print(f\"mu_1: {mu_1}\")\n",
    "print(f\"sigma_1: {sigma_1}\")\n",
    "\n",
    "# a type 2 error means we fail to reject the null hypothesis,\n",
    "# which will happen when X is still in our original interval\n",
    "type_2_probability = normal_probability_between(low, high, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability   # not making a type 2 error\n",
    "power\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next case, what happens to the *power* of the test, if the coin \n",
    "is not biased toward heads, or that $p \\leq 0.5$.\n",
    "In that case we want a *one-sided test* that rejects the null \n",
    "hypothesis when $X$ is much larger than 500 but not when $X$\n",
    "is smaller than 500.\n",
    "\n",
    "Null hypothesis ($H_0$): $p \\leq 0.5$    \n",
    "Alternative hypotehsis ($H_1$): $p > 0.5$   \n",
    "(in fact we have $p = 0.55$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high_one_sided: 526\n"
     ]
    }
   ],
   "source": [
    "# With 5% significance test (one-sided test)\n",
    "# The result is smaller than two-sided test because we need more\n",
    "# probability in the upper tail (5% only for high tail side)\n",
    "high_one_sided = normal_upper_bound(0.95, mu_0, sigma_0)\n",
    "print(f\"high_one_sided: {high_one_sided:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the power of the test: 0.9363794803307173\n"
     ]
    }
   ],
   "source": [
    "# a type 2 error means we fail to reject the null hypothesis \n",
    "# for this one-side test, the null hypothesis is p <= 0.5\n",
    "# which will happen when X is still below the upper bound of\n",
    "# original interval (p = 0.5)\n",
    "type_2_probability_one_sided = normal_probability_below(high_one_sided, \n",
    "  mu_1, sigma_1)\n",
    "\n",
    "power = 1 - type_2_probability_one_sided   # not making type 2 error \n",
    "                                           # one-sided\n",
    "print(f\"the power of the test: {power}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing to the previous one, the test is more powerful \n",
    "that it no longer reject $H_0 (p \\leq 0.5)$  when $X$ is below\n",
    "469 (which is very unlikely to happen if $H_1$ is true)\n",
    "and instead reject $H_0$ when $X$ is between 526 and 531 \n",
    "(which is somewhat likely to happen if $H_1$ is true)\n",
    "\n",
    "In the above example $H_1$ is true (p = 0.55 > 0.5)\n",
    "and we have high probability for that alternative hypothesis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## p-Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sided_p_value(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "  \"\"\" \n",
    "  How likely are we to see a value at least as extreme as x (in either\n",
    "  direction) if our values are from an N(mu, sigma)?\n",
    "  \"\"\" \n",
    "  if x >= mu:\n",
    "    # x is greater than mean, so the tail is everything greater than x\n",
    "    return 2 * normal_probability_above(x, mu, sigma)\n",
    "\n",
    "  else:\n",
    "    # x is less than the mean, so the tail is everything less than x\n",
    "    return 2 * normal_probability_below(x, mu, sigma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to see 530 heads, we could compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06207721579598835"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a value 529.5 instead of 530 because\n",
    "# of continuity correction. It is better to estimate\n",
    "# using P(529.5 <= X < 530.5) rather than  P(530 <= X <= 531)\n",
    "two_sided_p_value(529.5, mu_0, sigma_0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simulation to show this *p-value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extreme_value_count: 60\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(2023_03_23)\n",
    "\n",
    "extreme_value_count = 0\n",
    "for _ in range(1_000):\n",
    "  num_heads = sum(1 if rng.random() < 0.5 else 0    # Count # of heads\n",
    "                  for _ in range(1_000))            # in 1000 flips\n",
    "\n",
    "  if num_heads >= 530 or num_heads <= 470:  # and count how oftern\n",
    "    extreme_value_count += 1                # the # is `extreme`\n",
    "\n",
    "# p-value was 0.062 => ~= 62 extreme values out of 1_000\n",
    "print(f\"extreme_value_count: {extreme_value_count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the *p-value* = 0.062 is greater than our 5% significance,\n",
    "we don't reject the null.\n",
    "\n",
    "If we instead saw 532 heads, the *p-value* would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046345287837786575"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(531.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one-sided test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_p_value = normal_probability_above \n",
    "lower_p_value = normal_probability_below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06062885772582072"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we saw 525 heads (one-sided test)\n",
    "# We wouldn't reject the null (0.06 > 0.05)\n",
    "upper_p_value(524.5, mu_0, sigma_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04686839508859242"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we saw 527 heads (one-sided test)\n",
    "# we would reject the null (0.04 < 0.05)\n",
    "upper_p_value(526.5, mu_0, sigma_0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "For example, we want to know the coin is fair or not.   \n",
    "By flipping 1_000 times, we observe 525 heads.   \n",
    "We don't know the $p$, and we use our estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu: 0.525\n",
      "sigma: 0.015791611697353755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4940490278129096, 0.5559509721870904)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hat = 525 / 1_000\n",
    "mu = p_hat\n",
    "sigma = np.sqrt(p_hat * (1 - p_hat) / 1000)\n",
    "\n",
    "print(f\"mu: {mu}\")\n",
    "print(f\"sigma: {sigma}\")\n",
    "\n",
    "# Using 95% cconfident\n",
    "normal_two_sided_bounds(0.95, mu, sigma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, we do not conclude that the coins is unfair, since\n",
    "0.5 falls within our confidence interval.\n",
    "\n",
    "If instead, we had seen 540 heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5091095927295919, 0.5708904072704082)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hat = 540 / 1_000\n",
    "mu = p_hat\n",
    "sigma = np.sqrt(p_hat * (1 - p_hat) / 1_000)\n",
    "normal_two_sided_bounds(0.95, mu, sigma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \"fair coin\" doesn't lie in the confidence interval. \n",
    "(The \"fair coin\" hypothesis doesn't pass a test that you would\n",
    "expect it to pass 95% of the time if it were true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-Hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(rng) -> List[bool]:\n",
    "  \"\"\"Flips a fair coin 1_000 times, True = heads, False = tails\"\"\" \n",
    "  return rng.random(1_000) < 0.5\n",
    "\n",
    "def reject_fairness(experiment: List[bool]) -> bool:\n",
    "  \"\"\"\n",
    "  Using the 5% significance levels.\n",
    "  Interval is computer from `normal_two_sided_bounds(0.95, mu_0, sigma_0)`\n",
    "  where mu_0, sigma_0 are computed from\n",
    "  \n",
    "  \"\"\" \n",
    "  num_heads = sum(experiment) \n",
    "  return num_heads < 469 or num_heads > 531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(2023_03_23)\n",
    "experiments = [run_experiment(rng) for _ in range(1_000)]\n",
    "num_rejections = len([experiment for experiment in experiments\n",
    "                     if reject_fairness(experiment)])\n",
    "\n",
    "num_rejections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Running an A/B Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
