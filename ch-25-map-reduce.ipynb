{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs   \n",
    "- [2023/03/08]   \n",
    "  Restart this notebook if you change the scratch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Iterator, Tuple, Iterable, Callable, Any, NamedTuple\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we have a collection of items we'd like to process somehow.     \n",
    "For instance, the items might be website logs, the texts of various books,    \n",
    "image files, or anything else. \n",
    "\n",
    "A basic version of the MapReduce algorithm consists of the following steps:\n",
    "1. Use a `mapper` function to turn each item into zero or more key/values pairs.   \n",
    "2. Collect together all the pairs with identical keys.\n",
    "3. Use a `reducer` function on each collction of grouped values to produces     \n",
    "   output values for the corresponding key.\n",
    "\n",
    "In the following examples, we try to count how many word occurrence for a given    \n",
    "texts. The first step is defines as a function `wc_mapper`, it will emit on    \n",
    "each words after tokenizing into a tuple `(_word_, 1)`.    \n",
    "Step 2 is embedded inside `word_count` function as a nested loop to append     \n",
    "for each occurrence as a long list of ones.    \n",
    "Step 3 is defined as `wc_reducer` that will count the length of the long list   \n",
    "of ones."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(document: str) -> List[str]:\n",
    "  \"\"\"Just split on whitespace\"\"\" \n",
    "  return document.split()\n",
    "\n",
    "\n",
    "def word_count_old(documents: List[str]):\n",
    "  \"\"\"Word count not using MapReduce\"\"\" \n",
    "  return Counter(word for document in documents\n",
    "                  for word in tokenize(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_mapper(document: str) -> Iterator[Tuple[str, int]]:\n",
    "  \"\"\"For each word in the document, emit (word, 1)\"\"\" \n",
    "  for word in tokenize(document):\n",
    "    yield (word, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wc_reducer(word: str, counts: Iterable[int]) -> Iterator[Tuple[str, int]]:\n",
    "  \"\"\"Sum up the counts for a word\"\"\" \n",
    "  yield (word, sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(documents: List[str], verbose: bool = False) -> List[Tuple[str, int]]:\n",
    "  \"\"\"Count the word in the input documents using MapReduce\"\"\" \n",
    "  collector = defaultdict(list)       # To store grouped values\n",
    "\n",
    "  for document in documents:\n",
    "    for word, count in wc_mapper(document):\n",
    "      collector[word].append(count)\n",
    "\n",
    "  if verbose:\n",
    "    display(collector)  \n",
    "\n",
    "  return [output for word, counts in collector.items()\n",
    "            for output in wc_reducer(word, counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 1), ('science', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "sample_documents = [\"data science\", \"big data\", \"science fiction\"]\n",
    "\n",
    "list(wc_mapper(sample_documents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'data': [1, 1], 'science': [1, 1], 'big': [1], 'fiction': [1]})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wc_count_out = word_count(sample_documents, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 2), ('science', 2), ('big', 1), ('fiction', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_count_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why MapReduce?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine now that our billions of documents are scattered across 100 machines.\n",
    "\n",
    "The algorithm can scales horizontally: If we double the number of\n",
    "machines, then (ignoring certain fixed costs of running MapReduce system)    \n",
    "our computation should run approximately twice as fast."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce More Generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A key/value pair is just 2-tuple\n",
    "KV = Tuple[Any, Any]\n",
    "\n",
    "# A Mapper is a function that returns an Iterable of key/value pairs\n",
    "Mapper = Callable[..., Iterable[KV]]\n",
    "\n",
    "# A Reducer is a function that takes a key and an iterable of values\n",
    "# and returns a kye/value pair\n",
    "Reducer = Callable[[Any, Iterable], KV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reduce(inputs: Iterable, mapper: Mapper, reducer: Reducer) -> List[KV]:\n",
    "  \"\"\"Run MapReduce of the inputs using mapper and reducer\"\"\" \n",
    "  collector = defaultdict(list)\n",
    "\n",
    "  for _input in inputs:\n",
    "    for key, value in mapper(_input):\n",
    "      collector[key].append(value)\n",
    "\n",
    "  return [output for key, values in collector.items()\n",
    "            for output in reducer(key, values)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the general version of MapReduce with user-defined \n",
    "`wc_mapper` and `wc_reducer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', 2), ('science', 2), ('big', 1), ('fiction', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = map_reduce(sample_documents, wc_mapper, wc_reducer)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(key, values: Iterable, values_fn: Callable) -> KV:\n",
    "  return (key, values_fn(values))\n",
    "\n",
    "def values_reducer(values_fn: Callable) -> Reducer:\n",
    "  \"\"\"Return a reducer that just applies values_fn to its valeus\"\"\"\n",
    "  return lambda key, values: reduce(key, values, values_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_reducer = values_reducer(sum)\n",
    "max_reducer = values_reducer(max)\n",
    "min_reducer = values_reducer(min)\n",
    "count_distinct_reducer = values_reducer(lambda values: len(set(values)))\n",
    "\n",
    "assert sum_reducer(\"key\", [1, 2, 3, 3]) == (\"key\", 9)\n",
    "assert min_reducer(\"key\", [1, 2, 3, 3]) == (\"key\", 1)\n",
    "assert max_reducer(\"key\", [1, 2, 3, 3]) == (\"key\", 3)\n",
    "assert count_distinct_reducer(\"key\", [1, 2, 3, 3]) == (\"key\", 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Analyzing Status Updates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future I will try to compile a dataset to demonstrate this\n",
    "analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Matrix Multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a *sparse* matrix to store matrix efficiently and performing\n",
    "MapReduce algorithm onit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entry(NamedTuple):\n",
    "  name: str \n",
    "  i: int \n",
    "  j: int \n",
    "  value: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_mapper(entry: Entry, num_rows_a, num_cols_b):\n",
    "  if entry.name == \"A\":\n",
    "    for y in range(num_cols_b):\n",
    "      key = (entry.i, y)                # which element of C\n",
    "      value = (entry.j, entry.value)    # which entry in the sum\n",
    "      yield (key, value)\n",
    "\n",
    "  else: \n",
    "    for x in range(num_rows_a):\n",
    "      key = (x, entry.j)                # which element of C\n",
    "      value = (entry.i, entry.value)    # which entry in the sum\n",
    "      yield (key, value)\n",
    "\n",
    "def matrix_multiply_mapper(num_rows_a: int, num_cols_b: int) -> Mapper:\n",
    "  # C[x][y] = A[x][0] * B[0][y] + ... + A[x][m] * B[m][y]\n",
    "  #\n",
    "  # so an element A[i][j] goes into every C[i][y] with coef B[j][y]\n",
    "  # and an element B[i][j] goes into every C[x][j] with coef A[x][i]\n",
    "  return lambda entry: matrix_mapper(entry, num_rows_a, num_cols_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiply_reducer(key: Tuple[int, int], \n",
    "                            indexed_values: Iterable[Tuple[int, int]]):\n",
    "  results_by_index = defaultdict(list)\n",
    "\n",
    "  for index, value in indexed_values:\n",
    "    results_by_index[index].append(value)\n",
    "  \n",
    "  # Multiply the values for positions with two values\n",
    "  # (one from A, and one from B) and sum them up\n",
    "  sumproduct = sum(values[0] * values[1] \n",
    "                    for values in results_by_index.values()\n",
    "                    if len(values) == 2)\n",
    "\n",
    "  if sumproduct != 0.0:\n",
    "    yield (key, sumproduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[3, 2, 0],\n",
    "     [0, 0, 0]]\n",
    "\n",
    "B = [[4, -1, 0],\n",
    "     [10, 0, 0],\n",
    "     [0, 0, 0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [Entry(\"A\", 0, 0, 3), Entry(\"A\", 0, 1, 2), Entry(\"B\", 0, 0, 4),\n",
    "            Entry(\"B\", 0, 1, -1), Entry(\"B\", 1, 0, 10)]\n",
    "\n",
    "mapper = matrix_multiply_mapper(num_rows_a=2, num_cols_b=3)\n",
    "reducer = matrix_multiply_reducer\n",
    "\n",
    "# Product should be ([32, -3, 0], [0, 0, 0])\n",
    "assert (set(map_reduce(entries, mapper, reducer)) == {((0, 1), -3), ((0, 0), 32)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Aside: Combiners"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
