{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs   \n",
    "- [2023/03/08]   \n",
    "  Restart this notebook if you change the scratch library\n",
    "\n",
    "- [2024/03/22]   \n",
    "  You do not need to restart this notebook when you change the scratch library\n",
    "\n",
    "To do:  \n",
    "- Make the explanation aligns with the simple example from StatQuest with Josh Starmer   \n",
    "  [Naive Bayes, Clearly Explained](https://www.youtube.com/watch?v=O2L2Uv9pdDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import requests\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Set, NamedTuple, List, Tuple, Dict, Iterable \n",
    "from collections import defaultdict, Counter\n",
    "from io import BytesIO\n",
    "from scratch.machine_learning import MachineLearning as ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({\n",
    "  'font.size': 16,\n",
    "  'grid.alpha': 0.25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Realy Dumb Spam Filter\n",
    "\n",
    "$S$ be the event \"the message is spam.\"   \n",
    "$B$ be the event \"the message contains the word *bitcon*.\"\n",
    "\n",
    "Conditional probability that the message is spam conditional on \n",
    "containing the word *bitcoin* (using Bayes' theorem)  \n",
    "\n",
    "$$\n",
    "  P(S|B) \n",
    "    = \\frac{P(B|S) P(S)}{ P(B) }\n",
    "    = \\frac{P(B|S) P(S)}{ P(B|S) P(S) + P(B|\\neg S) P(\\neg S)}\n",
    "$$\n",
    "\n",
    "numerator: the probability that a message is spam *and* contains *bitcoin*  \n",
    "denominator: the probability that a message contains *bitcoin*.\n",
    "\n",
    "If we have a large collection of messages we know are spam, and a large\n",
    "collection of messages we know are not spam, then we can easily\n",
    "estimate $P(B|S)$ and $P(B|\\neg S)$. If we further assume that any\n",
    "message is equally likely to be spam are not spam \n",
    "(so that $P(S) = P(\\neg S) = 0.5$), then\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  P(S|B) &= \\frac{P(B|S) 0.5}{ P(B|S) 0.5 + P(B|\\neg S) 0.5} \\nonumber \\\\\n",
    "         &= \\frac{P(B|S)}{P(B|S) + P(B|\\neg S)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If 50% of spam messages have the word *bitcoin*, but  only 1% of nonspam\n",
    "messages do, then the probability that any given *bitcon*-containing\n",
    "email is spam is:\n",
    "\n",
    "$$\n",
    "  P(S|B) = \\frac{0.5}{0.5 + 0.01} = 98\\%\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this classifier so dumb? because it only uses a word \"bitcoin\"    \n",
    "and with a high confidence (98%) if a message containing a word \"bitcoin\",    \n",
    "this spam filter predicts it 98% most of the time as a spam message   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A More Sophisticated Spam Filter\n",
    "\n",
    "$X_i$ is the event \"a message contains the word $w_i$.\"     \n",
    "$P(X_i | S)$ is the probability that a spam message contains the $i$-th word     \n",
    "$P(X_i | \\neg S)$ is the probability that a nonspam message contains the $i$-th word.\n",
    "\n",
    "The key to Naive Bayes is making the (big) assumption that the presences   \n",
    "(or absences) of each word are *independent* of one another, *conditional* on   \n",
    "a message being spam or not.\n",
    "\n",
    "Intuitvely, this assumption means that knowing whether a certain spam message   \n",
    "contains the word **bitcon** gives us **no information** about whether the same   \n",
    "message contains the word **rolex**.\n",
    "\n",
    "In math, we can write\n",
    "\n",
    "$$\n",
    "  P(X_1 = x_1, \\ldots, X_n = x_n | S) \n",
    "    = P(X_1 = x_1 | S) \\times \\cdots \\times P(X_n = x_n | S)\n",
    "$$\n",
    "\n",
    "\n",
    "Multiplying many probabilities will give raise a problem of *underflow*   \n",
    "(not _overflow_, because the probability is less than 1).  More friendly approach   \n",
    "to multiply probabilities, is to use the identities $p_i = \\exp\\{\\log(p_i)\\}$.   \n",
    "Then we can transform multiplication into addition\n",
    "\n",
    "$$\n",
    "  p_i \\times \\cdots \\times p_n \n",
    "    = \\exp\\{\\log(p_1) + \\ldots + \\log(p_n)\\}\n",
    "$$\n",
    "\n",
    "Only one problem left to use the above formula. Imagine that in our training set    \n",
    "the vocabulary word _data_ only occurs in nonspam message. Then we would estimate   \n",
    "$P(\\textrm{data}|S) = 0$. The result is that our Naive Bayes classifier would always  \n",
    "assign spam probability 0 to _any_message containing the word _data_, even  \n",
    "a message like \"data on free bitcon and authentic rolex watches\". To avoid this   \n",
    "problem, we need some kind of smoothing, which is a concept of _pseducount_ enter  \n",
    "the game.\n",
    "\n",
    "*pseudocount* is a way to avoid an extreme condition (probability zero) when   \n",
    "an event doesn't  occur given another event happens, but it occurs given\n",
    "another even does not happe or vice versa.  \n",
    "\n",
    "*pseudocount* $k$ can be formulated like this\n",
    "$$\n",
    "  P(X_i|S) = \\frac{k + \\text{number of spams containing } w_i}{2k + \\text{number of spams}}\n",
    "$$\n",
    "We also do the same for $P(X_i | \\neg S)$.   \n",
    "When computing the spam probabilities for the $i$-th word, we assume we also saw  \n",
    "$k$ additional nonspams containing the word and $k$ additional nonspams not   \n",
    "containing the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 24_03_27\n",
    "rng = np.random.default_rng(seed)\n",
    "p_i = rng.random(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0616069349833837e-42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(p_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-95.98508816151549"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.log(p_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(np.log(2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data', 'is', 'science'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a tokenization\n",
    "def tokenize(text: str) -> Set[str]:\n",
    "  text = text.lower()                         # convert to lowercase\n",
    "  all_words = re.findall(\"[a-z0-9]+\", text)   # extract the words, and\n",
    "  return set(all_words)\n",
    "\n",
    "\n",
    "tokenize(\"Data Science is science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a type of the training data\n",
    "class Message(NamedTuple):\n",
    "  text: str\n",
    "  is_spam: bool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We name the nonspam emails has *ham* emails. We also make a class\n",
    "for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "  def __init__(self, k: float = 0.5) -> None:\n",
    "    self.k = k    # smoothing factor / pseudocount\n",
    "\n",
    "    self.tokens: Set[str] = set()\n",
    "    self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "    self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "    self.spam_messages = self.ham_messages = 0\n",
    "\n",
    "  \n",
    "  def train(self, messages: Iterable[Message]) -> None:\n",
    "    for message in messages:\n",
    "      # Increment message counts\n",
    "      if message.is_spam:\n",
    "        self.spam_messages += 1\n",
    "      else:\n",
    "        self.ham_messages += 1\n",
    "\n",
    "      # Increment word counts\n",
    "      for token in tokenize(message.text):\n",
    "        self.tokens.add(token)\n",
    "        if message.is_spam:\n",
    "          self.token_spam_counts[token] += 1\n",
    "        else:\n",
    "          self.token_ham_counts[token] += 1\n",
    "\n",
    "\n",
    "  def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "    \"\"\"returns P(token | spam) and P(token | ham)\"\"\" \n",
    "    spam = self.token_spam_counts[token]\n",
    "    ham = self.token_ham_counts[token]\n",
    "\n",
    "    p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "    p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "\n",
    "    return p_token_spam, p_token_ham\n",
    "\n",
    "\n",
    "  def predict(self, text: str) -> float:\n",
    "    text_tokens = tokenize(text)\n",
    "    log_prob_if_spam = 0.0\n",
    "    log_prob_if_ham = 0.0\n",
    "\n",
    "    # Iterate through each word in our vocabulary\n",
    "    for token in self.tokens:\n",
    "      prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "\n",
    "      # If `token` appears in the message,\n",
    "      # add the log probability of `seeing`` it\n",
    "      if token in text_tokens:\n",
    "        log_prob_if_spam += np.log(prob_if_spam)\n",
    "        log_prob_if_ham += np.log(prob_if_ham)\n",
    "\n",
    "      # Otherwise add the log probability of `not seeing` it,\n",
    "      # which is log(1 - probability of seeing it)\n",
    "      else:\n",
    "        log_prob_if_spam += np.log(1.0 - prob_if_spam)\n",
    "        log_prob_if_ham += np.log(1.0 - prob_if_ham)\n",
    "\n",
    "    \n",
    "    prob_if_spam = np.exp(log_prob_if_spam)\n",
    "    prob_if_ham = np.exp(log_prob_if_ham)\n",
    "\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Model\n",
    "\n",
    "Test the model to some unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['spam rules', True], ['ham rules', False], ['hello ham', False]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[\"spam rules\",  True],\n",
    " [ \"ham rules\", False],\n",
    " [ \"hello ham\", False]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [Message(\"spam rules\", True),\n",
    "            Message(\"ham rules\", False),\n",
    "            Message(\"hello ham\", False)]\n",
    "\n",
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(text='spam rules', is_spam=True),\n",
       " Message(text='ham rules', is_spam=False),\n",
       " Message(text='hello ham', is_spam=False)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that it got the counts right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabularies {'ham', 'rules', 'hello', 'spam'}\n",
      "spam 1\n",
      "ham 2\n",
      "spam defaultdict(<class 'int'>, {'rules': 1, 'spam': 1})\n",
      "ham defaultdict(<class 'int'>, {'ham': 2, 'rules': 1, 'hello': 1})\n"
     ]
    }
   ],
   "source": [
    "print(\"vocabularies\", model.tokens)\n",
    "print(\"spam\", model.spam_messages)\n",
    "print(\"ham\", model.ham_messages)\n",
    "print(\"spam\", model.token_spam_counts)\n",
    "print(\"ham\", model.token_ham_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a prediction. We also (laboriously) go through our Naive Bayes logic by hand.   \n",
    "In here, we set $k = 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "  P(X_i|S) = \\frac{k + \\text{number of spams containing } w_i}{2k + \\text{number of spams}} \\\\[12pt]\n",
    "  P(X_i|\\neg S) = \\frac{k + \\text{number of ham containing } w_i}{2k + \\text{number of hams}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8350515463917525\n",
      "0.8350515463917525\n"
     ]
    }
   ],
   "source": [
    "text = \"hello spam\"\n",
    "\n",
    "# test for all vocabularies: {\"spam\", \"ham\", \"rules\", \"hello\"}\n",
    "probs_if_spam = [\n",
    "  (1 + 0.5) / (1 + 2 * 0.5),          # \"spam\"   (present in \"text\")\n",
    "  1 - (0 + 0.5) / (1 + 2 * 0.5),      # \"ham\"    (not present in \"text\")\n",
    "  1 - (1 + 0.5) / (1 + 2 * 0.5),      # \"rules\"  (not present in \"text\")   # number of spams with \"rules\"\n",
    "  (0 + 0.5) / (1 + 2 * 0.5)           # \"hello\"  (present)  # number of spams with \"hello\" is 0\n",
    "]\n",
    "\n",
    "probs_if_ham = [\n",
    "  (0 + 0.5) / (2 + 2 * 0.5),          # \"spam\"   (present)\n",
    "  1 - (2 + 0.5) / (2 + 2 * 0.5),      # \"ham\"    (not present)\n",
    "  1 - (1 + 0.5) / (2 + 2 * 0.5),      # \"rules\"  (not present)\n",
    "  (1 + 0.5) / (2 + 2 * 0.5)           # \"hello\"  (present)\n",
    "]\n",
    "\n",
    "p_if_spam = np.exp(sum(np.log(p) for p in probs_if_spam))\n",
    "p_if_ham = np.exp(sum(np.log(p) for p in probs_if_ham))\n",
    "\n",
    "print(model.predict(text))\n",
    "print(p_if_spam / (p_if_spam + p_if_ham))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Our Model \n",
    "\n",
    "Download and unpack spam dataset from [SpamAssassin public corpus](https://spamassassin.apache.org/old/publiccorpus/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
    "         \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\"]\n",
    "\n",
    "# This is where the data will end up\n",
    "# in /spam, /easy_ham, and /hard_ham subdirectories.\n",
    "# Change this to where you want the data.\n",
    "OUTPUT_DIR = 'spam_data'\n",
    "\n",
    "for filename in FILES:\n",
    "  # Use requests to get the file contents at each URL\n",
    "  content = requests.get(f\"{BASE_URL}/{filename}\").content \n",
    "\n",
    "  # Wrap the in-memory bytes so we can use them as a \"file.\"\n",
    "  fin = BytesIO(content)\n",
    "\n",
    "  # And extract all the files to the specified output dir.\n",
    "  with tarfile.open(fileobj=fin, mode=\"r:bz2\") as tf:\n",
    "    tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things *really* simple, we'll just look at the subject lines\n",
    "each email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the path to whatever you've put the files\n",
    "path = \"spam_data/*/*\"\n",
    "\n",
    "data: List[Message] = []\n",
    "\n",
    "# -- computational time 32 secs\n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for filename in glob.glob(path):\n",
    "  is_spam = \"ham\" not in filename\n",
    "\n",
    "  # There are some garbage characters in the emails; the errors='ignore'\n",
    "  # skips them instead of raising an exception.\n",
    "  with open(filename, errors='ignore') as email_file:\n",
    "    for line in email_file:\n",
    "      if line.startswith(\"Subject:\"):\n",
    "        subject = line.lstrip(\"Subject: \")\n",
    "        data.append(Message(subject, is_spam))\n",
    "        break   # done with this file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dataset by splitting into training and testing.\n",
    "After that we ready to train the dataset with the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023_04_19\n",
    "rng = np.random.default_rng(seed)\n",
    "train_messages, test_messages = ml.split_data(data, 0.75, rng)\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(train_messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some predictions and check how the model does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(False, False): 676, (True, True): 78, (True, False): 41, (False, True): 30})\n"
     ]
    }
   ],
   "source": [
    "predictions = [(message, model.predict(message.text))\n",
    "               for message in test_messages]\n",
    "\n",
    "# Assume that spam_probability > 0.5 corresponds to spam prediction\n",
    "# and count the combinations of (actual is_spam, predicted is_spam)\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                           for message, spam_probability in predictions)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam classified as `spam` (true positive):  78\n",
      "ham classified as `spam` (false positive):  30\n",
      "ham classified as `ham`   (true negative): 676\n",
      "spam classified as `ham` (false negative):  41\n"
     ]
    }
   ],
   "source": [
    "print(f\"spam classified as `spam` (true positive): {confusion_matrix[True, True]:>3d}\")\n",
    "print(f\"ham classified as `spam` (false positive): {confusion_matrix[False, True]:>3d}\")\n",
    "print(f\"ham classified as `ham`   (true negative): {confusion_matrix[False, False]:>3d}\")\n",
    "print(f\"spam classified as `ham` (false negative): {confusion_matrix[True, False]:>3d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.72\n",
      "Recall: 0.66\n"
     ]
    }
   ],
   "source": [
    "true_positive = confusion_matrix[True, True]\n",
    "false_positive = confusion_matrix[False, True]\n",
    "false_negative = confusion_matrix[True, False]\n",
    "\n",
    "print(f\"Precision: {true_positive / (true_positive + false_positive):.2f}\")\n",
    "print(f\"Recall: {true_positive / (true_positive + false_negative):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_words ['needed', 'assistance', 'mortgage', 'attn', 'clearance', 'sale', 'systemworks', 'money', 'rates', 'adv']\n",
      "hammiest_words ['spambayes', 'users', 'was', 'razor', 'zzzzteana', 'sadev', 'apt', 'ouch', 'perl', 'bliss']\n"
     ]
    }
   ],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "  # We probabily shouldn't call private methods, but it's for a good cause\n",
    "  prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "\n",
    "  return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "\n",
    "\n",
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "\n",
    "print(f\"spammiest_words {words[-10:]}\")\n",
    "print(f\"hammiest_words {words[:10]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better improvement of spam filter above\n",
    "1. Include message body, not only message subject line\n",
    "2. Accept a token that has occurrence above some threshold\n",
    "3. Similarity word should be reduced to its basic form (do stemming).\n",
    "   Popular algorithm using Porter stemmer algorithm\n",
    "4. Try another feature instead an event of \"message contains word $w_i$.\"\n",
    "   We can improve by adding number as a feature.\n",
    "   More complex architecture, of course, using deep learing. \n",
    "   We will save it for another time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
