{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs   \n",
    "- [2023/03/08]   \n",
    "  Restart this notebook if you change the scratch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import requests\n",
    "import tarfile\n",
    "\n",
    "from typing import Set, NamedTuple, List, Tuple, Dict, Iterable \n",
    "from collections import defaultdict, Counter\n",
    "from io import BytesIO\n",
    "from scratch.machine_learning import MachineLearning as ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Realy Dumb Spam Filter\n",
    "\n",
    "$S$ be the event \"the message is spam.\"   \n",
    "$B$ be the event \"the message contains the word *bitcon*.\"\n",
    "\n",
    "Conditional probability that the message is spam conditional on \n",
    "containing the word *bitcoin*  \n",
    "\n",
    "$$\n",
    "  P(S|B) = \\frac{P(B|S) P(S)}{ P(B|S) P(S) + P(B|\\neg S) P(\\neg S)}\n",
    "$$\n",
    "\n",
    "numerator: the probability that a message is spam *and* contains *bitcoin  \n",
    "denominator: the probability that a message contains *bitcoin*.\n",
    "\n",
    "If we have a large collection of messages we know are spam, and a large\n",
    "collection of messages we know are not spam, then we can easily\n",
    "estimate $P(B|S)$ and $P(B|\\neg S)$. If we further assume that any\n",
    "message is equally likely to be spam are not spam \n",
    "(so that $P(S) = P(\\neg S) = 0.5$), then\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  P(S|B) &= \\frac{P(B|S) 0.5}{ P(B|S) 0.5 + P(B|\\neg S) 0.5} \\\\\n",
    "         &= \\frac{P(B|S)}{P(B|S) + P(B|\\neg S)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "If 50% of spam messages have the word *bitcoin*, but  only 1% of nonspam\n",
    "messages do, then the probability that any given *bitcon*-containing\n",
    "email is spam is:\n",
    "\n",
    "$$\n",
    "  P(S|B) = \\frac{0.5}{0.5 + 0.01} = 98\\%\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A More Sophisticated Spam Filter\n",
    "\n",
    "$X_i$ is the event \"a message contains the word $w_i$.\"     \n",
    "$P(X_i | S)$ is the probability that a spam message contains the $i$-th\n",
    "word     \n",
    "$P(X_i | \\neg S)$ is the probability that a nonspam message contains\n",
    "the $i$-th word.\n",
    "\n",
    "The key to Naive Bayes is making the (big) assumption that the presences\n",
    "(or absences) of each word are *independent* of one another, \n",
    "*conditional* on a message being spam or not.\n",
    "\n",
    "Intuitvely, this assumption means that knowing whether a certain\n",
    "spam message contains the word *bitcon* gives us **no information**\n",
    "about whether the same message contains the word **rolex**.\n",
    "\n",
    "In math, we can write\n",
    "\n",
    "$$\n",
    "  P(X_1 = x_1, \\ldots, X_n = x_n | S) \n",
    "    = P(X_1 = x_1 | S) \\times \\cdots \\times P(X_n = x_n | S)\n",
    "$$\n",
    "\n",
    "\n",
    "Multiplying many probabilities will give raise a problem of *underflow*.\n",
    "More friendly approach to multiply probabilities, is to use the \n",
    "identities $p_i = \\exp\\{\\log(p_i)\\}$. Then we can transform multiplication\n",
    "into addition\n",
    "\n",
    "$$\n",
    "  p_i \\times \\cdots \\times p_n \n",
    "    = \\exp\\{\\log(p_1) + \\ldots + \\log(p_n)\\}\n",
    "$$\n",
    "\n",
    "*pseudocount* is a way to avoid an extremen condition\n",
    "when an event doesn't occur when calculating conditional probability\n",
    "of that event according to another event."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data', 'is', 'science'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a tokenization\n",
    "def tokenize(text: str) -> Set[str]:\n",
    "  text = text.lower()                         # convert to lowercase\n",
    "  all_words = re.findall(\"[a-z0-9]+\", text)   # extract the words, and\n",
    "  return set(all_words)\n",
    "\n",
    "\n",
    "tokenize(\"Data Science is science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a type of the training data\n",
    "class Message(NamedTuple):\n",
    "  text: str\n",
    "  is_spam: bool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We name the nonspam emails has *ham* emails. We also make a class\n",
    "for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "  def __init__(self, k: float = 0.5) -> None:\n",
    "    self.k = k    # smoothing factor / pseudocount\n",
    "\n",
    "    self.tokens: Set[str] = set()\n",
    "    self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "    self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "    self.spam_messages = self.ham_messages = 0\n",
    "\n",
    "  \n",
    "  def train(self, messages: Iterable[Message]) -> None:\n",
    "    for message in messages:\n",
    "      # Increment message counts\n",
    "      if message.is_spam:\n",
    "        self.spam_messages += 1\n",
    "      else:\n",
    "        self.ham_messages += 1\n",
    "\n",
    "      # Increment word counts\n",
    "      for token in tokenize(message.text):\n",
    "        self.tokens.add(token)\n",
    "        if message.is_spam:\n",
    "          self.token_spam_counts[token] += 1\n",
    "        else:\n",
    "          self.token_ham_counts[token] += 1\n",
    "\n",
    "\n",
    "  def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "    \"\"\"returns P(token | spam) and P(token | ham)\"\"\" \n",
    "    spam = self.token_spam_counts[token]\n",
    "    ham = self.token_ham_counts[token]\n",
    "\n",
    "    p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "    p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "\n",
    "    return p_token_spam, p_token_ham\n",
    "\n",
    "\n",
    "  def predict(self, text: str) -> float:\n",
    "    text_tokens = tokenize(text)\n",
    "    log_prob_if_spam = 0.0\n",
    "    log_prob_if_ham = 0.0\n",
    "\n",
    "    # Iterate through each word in our vocabulary\n",
    "    for token in self.tokens:\n",
    "      prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "\n",
    "      # If `token` appears in the message,\n",
    "      # add the log probability of `seeing`` it\n",
    "      if token in text_tokens:\n",
    "        log_prob_if_spam += np.log(prob_if_spam)\n",
    "        log_prob_if_ham += np.log(prob_if_ham)\n",
    "\n",
    "      # Otherwise add the log probability of `not seeing` it,\n",
    "      # which is log(1 - probability of seeing it)\n",
    "      else:\n",
    "        log_prob_if_spam += np.log(1.0 - prob_if_spam)\n",
    "        log_prob_if_ham += np.log(1.0 - prob_if_ham)\n",
    "\n",
    "    \n",
    "    prob_if_spam = np.exp(log_prob_if_spam)\n",
    "    prob_if_ham = np.exp(log_prob_if_ham)\n",
    "\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Model\n",
    "\n",
    "Test the model to some unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [Message(\"spam rules\", is_spam=True),\n",
    "            Message(\"ham rules\", is_spam=False),\n",
    "            Message(\"hello ham\", is_spam=False)]\n",
    "\n",
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that it got the counts right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham', 'spam', 'rules', 'hello'}\n",
      "1\n",
      "2\n",
      "defaultdict(<class 'int'>, {'spam': 1, 'rules': 1})\n",
      "defaultdict(<class 'int'>, {'ham': 2, 'rules': 1, 'hello': 1})\n"
     ]
    }
   ],
   "source": [
    "print(model.tokens)\n",
    "print(model.spam_messages)\n",
    "print(model.ham_messages)\n",
    "print(model.token_spam_counts)\n",
    "print(model.token_ham_counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a prediction. We also (laboriously) go through our Naive\n",
    "Bayes logic by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8350515463917525\n",
      "0.8350515463917525\n"
     ]
    }
   ],
   "source": [
    "text = \"hello spam\"\n",
    "\n",
    "probs_if_spam = [\n",
    "  (1 + 0.5) / (1 + 2 * 0.5),          # \"spam\"   (present)\n",
    "  1 - (0 + 0.5) / (1 + 2 * 0.5),      # \"ham\"    (not present\n",
    "  1 - (1 + 0.5) / (1 + 2 * 0.5),      # \"rules\"  (not present)\n",
    "  (0 + 0.5) / (1 + 2 * 0.5)           # \"hello\"  (present)\n",
    "]\n",
    "\n",
    "probs_if_ham = [\n",
    "  (0 + 0.5) / (2 + 2 * 0.5),          # \"spam\"   (present)\n",
    "  1 - (2 + 0.5) / (2 + 2 * 0.5),      # \"ham\"    (not present)\n",
    "  1 - (1 + 0.5) / (2 + 2 * 0.5),      # \"rules\"  (not present)\n",
    "  (1 + 0.5) / (2 + 2 * 0.5)           # \"hello\"  (present)\n",
    "]\n",
    "\n",
    "p_if_spam = np.exp(sum(np.log(p) for p in probs_if_spam))\n",
    "p_if_ham = np.exp(sum(np.log(p) for p in probs_if_ham))\n",
    "\n",
    "print(model.predict(text))\n",
    "print(p_if_spam / (p_if_spam + p_if_ham))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Our Model \n",
    "\n",
    "Download and unpack spam dataset from [SpamAssassin public corpus](https://spamassassin.apache.org/old/publiccorpus/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
    "         \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\"]\n",
    "\n",
    "# This is where the data will end up\n",
    "# in /spam, /easy_ham, and /hard_ham subdirectories.\n",
    "# Change this to where you want the data.\n",
    "OUTPUT_DIR = 'spam_data'\n",
    "\n",
    "for filename in FILES:\n",
    "  # Use requests to get the file contents at each URL\n",
    "  content = requests.get(f\"{BASE_URL}/{filename}\").content \n",
    "\n",
    "  # Wrap the in-memory bytes so we can use them as a \"file.\"\n",
    "  fin = BytesIO(content)\n",
    "\n",
    "  # And extract all the files to the specified output dir.\n",
    "  with tarfile.open(fileobj=fin, mode=\"r:bz2\") as tf:\n",
    "    tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things *reallY* simple, we'll just look at the subject lines\n",
    "each email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the path to whatever you've put the files\n",
    "path = \"spam_data/*/*\"\n",
    "\n",
    "data: List[Message] = []\n",
    "\n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for filename in glob.glob(path):\n",
    "  is_spam = \"ham\" not in filename\n",
    "\n",
    "  # There are some garbage characters in the emails; the errors='ignore'\n",
    "  # skips them instead of raising an exception.\n",
    "  with open(filename, errors='ignore') as email_file:\n",
    "    for line in email_file:\n",
    "      if line.startswith(\"Subject:\"):\n",
    "        subject = line.lstrip(\"Subject: \")\n",
    "        data.append(Message(subject, is_spam))\n",
    "        break   # done with this file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the dataset by splitting into training and testing.\n",
    "After that we ready to train the dataset with the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2023_04_19\n",
    "rng = np.random.default_rng(seed)\n",
    "train_messages, test_messages = ml.split_data(data, 0.75, rng)\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(train_messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some predictions and check how the model does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(False, False): 688, (True, True): 80, (True, False): 29, (False, True): 28})\n"
     ]
    }
   ],
   "source": [
    "predictions = [(message, model.predict(message.text))\n",
    "               for message in test_messages]\n",
    "\n",
    "# Assume that spam_probability > 0.5 corresponds to spam prediction\n",
    "# and count the combinations of (actual is_spam, predicted is_spam)\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                           for message, spam_probability in predictions)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam classified as `spam` (true positive):  80\n",
      "ham classified as `spam` (false positive):  28\n",
      "ham classified as `ham`   (true negative): 688\n",
      "spam classified as `ham` (false negative):  29\n"
     ]
    }
   ],
   "source": [
    "print(f\"spam classified as `spam` (true positive): {confusion_matrix[True, True]:>3d}\")\n",
    "print(f\"ham classified as `spam` (false positive): {confusion_matrix[False, True]:>3d}\")\n",
    "print(f\"ham classified as `ham`   (true negative): {confusion_matrix[False, False]:>3d}\")\n",
    "print(f\"spam classified as `ham` (false negative): {confusion_matrix[True, False]:>3d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.74\n",
      "Recall: 0.73\n"
     ]
    }
   ],
   "source": [
    "true_positive = confusion_matrix[True, True]\n",
    "false_positive = confusion_matrix[False, True]\n",
    "false_negative = confusion_matrix[True, False]\n",
    "\n",
    "print(f\"Precision: {true_positive / (true_positive + false_positive):.2f}\")\n",
    "print(f\"Recall: {true_positive / (true_positive + false_negative):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_words ['zzzz', 'norton', 'attn', 'clearance', 'only', 'sale', 'money', 'systemworks', 'rates', 'adv']\n",
      "hammiest_words ['spambayes', 'users', 'razor', 'zzzzteana', 'sadev', 'ouch', 'apt', 'perl', 'bliss', 'wedded']\n"
     ]
    }
   ],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "  # We probabily shouldn't call private methods, but it's for a good cause\n",
    "  prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "\n",
    "  return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "\n",
    "\n",
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "\n",
    "print(f\"spammiest_words {words[-10:]}\")\n",
    "print(f\"hammiest_words {words[:10]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better improvement of spam filter above\n",
    "1. Include message body, not only message subject line\n",
    "2. Accept a token that has occurrence above some threshold\n",
    "3. Similarity word should be reduced to its basic form (do stemming).\n",
    "   Popular algorithm using Porter stemmer algorithm\n",
    "4. Try another feature instead an event of \"message contains word $w_i$.\"\n",
    "   We can improve by adding number as a feature.\n",
    "   More complex architecture, of course, using deep learing. \n",
    "   We will save it for another time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
